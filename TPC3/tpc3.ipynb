{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3881416-7587-47b6-b296-1095d78b32bb",
   "metadata": {},
   "source": [
    "## TPC 3 - Token's de Queries SPARQL (Análise Léxica)\n",
    "\n",
    "### Objetivo:\n",
    "Criar em Python um analisador léxico (tokenizer) para queries SPARQL, capaz de identificar os principais tokens de uma query, incluindo palavras-chave, variáveis, identificadores, literais, operadores, pontuação e quebras de linha.\n",
    "\n",
    "### Requisitos:\n",
    "\n",
    "- Implementar em Python usando a biblioteca re (expressões regulares)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45f82cdd-2bdd-4a3f-8260-b05389158895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30c539-4e60-4c4e-9ff3-6692a019c3fb",
   "metadata": {},
   "source": [
    "- Reconhecer os seguintes elementos da sintaxe básica de SPARQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4f28369-a2c1-4949-8d18-c3bd07c49b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\n",
    "        ('NEWLINE', r'\\n'),\n",
    "        ('SKIP', r'[ \\t]+'),\n",
    "        ('PREFIX', r'PREFIX\\b'),\n",
    "        ('SELECT', r'SELECT\\b'),\n",
    "        ('WHERE', r'WHERE\\b'),\n",
    "        ('OPTIONAL', r'OPTIONAL\\b'),\n",
    "        ('FILTER', r'FILTER\\b'),\n",
    "        ('VAR', r'\\?[a-zA-Z_][\\w]*'),     \n",
    "        ('URI', r'<[^>]*>'),              \n",
    "        ('IDENT', r':[a-zA-Z_][\\w]*'),    \n",
    "        ('INT', r'\\d+'),\n",
    "        ('STRING', r'\"[^\"]*\"'),\n",
    "        ('OP', r'[=!<>]+'),\n",
    "        ('PUNCT', r'[{}.;,]'),\n",
    "        ('ERRO', r'.')                    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c56da6-132a-462b-837e-0551d1498d5e",
   "metadata": {},
   "source": [
    "### Exemplo:\n",
    "\n",
    "**In:**\n",
    "```\n",
    "SELECT ?a ?b ?c WHERE \n",
    "{\n",
    "  ?a a :Pessoa ;\n",
    "     :temIdade ?b ;\n",
    "     :eIrmaoDe ?c .\n",
    "}\n",
    "```\n",
    "\n",
    "**Out:**\n",
    "```\n",
    "[('SELECT', 'SELECT', 0, (0, 6)),\n",
    " ('VAR', '?a', 0, (7, 9)),\n",
    " ('VAR', '?b', 0, (10, 12)),\n",
    " ('VAR', '?c', 0, (13, 15)),\n",
    " ('WHERE', 'WHERE', 0, (16, 21)),\n",
    " ('NEWLINE', '\\n', 1, (22, 23)),\n",
    " ('PUNCT', '{', 1, (23, 24)),\n",
    " ('NEWLINE', '\\n', 2, (24, 25)),\n",
    " ('VAR', '?a', 2, (27, 29)),\n",
    " ('ERRO', 'a', 2, (30, 31)),\n",
    " ('IDENT', ':Pessoa', 2, (32, 39)),\n",
    " ('PUNCT', ';', 2, (40, 41)),\n",
    " ('NEWLINE', '\\n', 3, (41, 42)),\n",
    " ('IDENT', ':temIdade', 3, (47, 56)),\n",
    " ('VAR', '?b', 3, (57, 59)),\n",
    " ('PUNCT', ';', 3, (60, 61)),\n",
    " ('NEWLINE', '\\n', 4, (61, 62)),\n",
    " ('IDENT', ':eIrmaoDe', 4, (67, 76)),\n",
    " ('VAR', '?c', 4, (77, 79)),\n",
    " ('PUNCT', '.', 4, (80, 81)),\n",
    " ('NEWLINE', '\\n', 5, (81, 82)),\n",
    " ('PUNCT', '}', 5, (82, 83)),\n",
    " ('NEWLINE', '\\n', 6, (83, 84))]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e03f38-0f4c-4f64-8eed-38414041ab27",
   "metadata": {},
   "source": [
    "### Implementação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "385b8b5f-698f-46fa-ada7-9bf154518229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SELECT', 'SELECT', 1, (0, 6)),\n",
       " ('VAR', '?a', 1, (7, 9)),\n",
       " ('VAR', '?b', 1, (10, 12)),\n",
       " ('VAR', '?c', 1, (13, 15)),\n",
       " ('WHERE', 'WHERE', 1, (16, 21)),\n",
       " ('NEWLINE', '\\n', 2, (22, 23)),\n",
       " ('PUNCT', '{', 2, (23, 24)),\n",
       " ('NEWLINE', '\\n', 3, (24, 25)),\n",
       " ('VAR', '?a', 3, (27, 29)),\n",
       " ('ERRO', 'a', 3, (30, 31)),\n",
       " ('IDENT', ':Pessoa', 3, (32, 39)),\n",
       " ('PUNCT', ';', 3, (40, 41)),\n",
       " ('NEWLINE', '\\n', 4, (41, 42)),\n",
       " ('IDENT', ':temIdade', 4, (47, 56)),\n",
       " ('VAR', '?b', 4, (57, 59)),\n",
       " ('PUNCT', ';', 4, (60, 61)),\n",
       " ('NEWLINE', '\\n', 5, (61, 62)),\n",
       " ('IDENT', ':eIrmaoDe', 5, (67, 76)),\n",
       " ('VAR', '?c', 5, (77, 79)),\n",
       " ('PUNCT', '.', 5, (80, 81)),\n",
       " ('NEWLINE', '\\n', 6, (81, 82)),\n",
       " ('PUNCT', '}', 6, (82, 83)),\n",
       " ('NEWLINE', '\\n', 7, (83, 84))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizerSPARQL(query):\n",
    "    reconhecidos = []\n",
    "    linha = 1\n",
    "    tokens = [\n",
    "        ('NEWLINE', r'\\n'),\n",
    "        ('SKIP', r'[ \\t]+'),\n",
    "        ('PREFIX', r'PREFIX\\b'),\n",
    "        ('SELECT', r'SELECT\\b'),\n",
    "        ('WHERE', r'WHERE\\b'),\n",
    "        ('OPTIONAL', r'OPTIONAL\\b'),\n",
    "        ('FILTER', r'FILTER\\b'),\n",
    "        ('VAR', r'\\?[a-zA-Z_][\\w]*'),     \n",
    "        ('URI', r'<[^>]*>'),              \n",
    "        ('IDENT', r':[a-zA-Z_][\\w]*'),    \n",
    "        ('INT', r'\\d+'),\n",
    "        ('STRING', r'\"[^\"]*\"'),\n",
    "        ('OP', r'[=!<>]+'),\n",
    "        ('PUNCT', r'[{}.;,]'),\n",
    "        ('ERRO', r'.')                    \n",
    "    ]\n",
    "    \n",
    "    token_regex = '|'.join(f'(?P<{name}>{pattern})' for name, pattern in tokens)\n",
    "    rc = re.finditer(token_regex, query)\n",
    "    for r in rc:\n",
    "        dic = r.groupdict()\n",
    "        tipo = None\n",
    "        valor = r.group()\n",
    "        for key in dic:\n",
    "            if dic[key]:\n",
    "                tipo = key\n",
    "                break\n",
    "        if tipo == 'NEWLINE':\n",
    "            linha += 1\n",
    "            reconhecidos.append((tipo, valor, linha, r.span()))\n",
    "        elif tipo != 'SKIP':\n",
    "            reconhecidos.append((tipo, valor, linha, r.span()))\n",
    "    \n",
    "    return reconhecidos\n",
    "    print(reconhecidos)\n",
    "\n",
    "query = \"\"\"SELECT ?a ?b ?c WHERE \n",
    "{\n",
    "  ?a a :Pessoa ;\n",
    "     :temIdade ?b ;\n",
    "     :eIrmaoDe ?c .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "tokenizerSPARQL(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
